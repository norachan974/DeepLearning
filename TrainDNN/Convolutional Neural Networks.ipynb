{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "button": false,
        "deletable": true,
        "id": "DDJwQPZcupab",
        "new_sheet": false,
        "run_control": {
          "read_only": false
        }
      },
      "source": [
        "# LIS 640 Applied Deep Learning : Convolutional Neural Networks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BaxWe-ygiHUs"
      },
      "source": [
        "# Code Blocks for Problem 4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "PEVr1sL5iHUs"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "\n",
        "class LeNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        ###################################################################\n",
        "        # TODO: Design your own network, define layers here.              #\n",
        "        # Some common Choices are: Linear, Conv2d, ReLU, MaxPool2d        #\n",
        "        ###################################################################\n",
        "        # Replace \"pass\" statement with your code\n",
        "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=20, kernel_size=5, padding=2, stride=1)\n",
        "        # second convolutional layer\n",
        "        self.conv2 = nn.Conv2d(in_channels=20, out_channels=50, kernel_size=5, padding=2, stride=1)\n",
        "        # max pooling layer\n",
        "        self.maxpool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        # fully connected layers\n",
        "        self.fc1 = nn.Linear(50 * 7 * 7, 500)  # The size 7x7 comes from the output of the second max pooling\n",
        "        self.fc2 = nn.Linear(500, 10)\n",
        "\n",
        "        ###################################################################\n",
        "        #                     END OF YOUR CODE                            #\n",
        "        ###################################################################\n",
        "\n",
        "    def forward(self,x):\n",
        "        ###################################################################\n",
        "        # TODO: Design your own network, implement forward pass here.     #\n",
        "        ###################################################################\n",
        "        # Replace \"pass\" statement with your code\n",
        "        x = self.maxpool(nn.functional.relu(self.conv1(x)))\n",
        "        # Apply second convolution ReLU and max pooling\n",
        "        x = self.maxpool(nn.functional.relu(self.conv2(x)))\n",
        "        # Flatten\n",
        "        x = torch.flatten(x, 1)\n",
        "        # fully connected layer ReLU\n",
        "        x = nn.functional.relu(self.fc1(x))\n",
        "        # fully connected layer\n",
        "        x = self.fc2(x)\n",
        "        ###################################################################\n",
        "        #                     END OF YOUR CODE                            #\n",
        "        ###################################################################\n",
        "        return x\n",
        "\n",
        "def train_epoch(inputs, labels, optimizer, loss_function):\n",
        "    ###################################################################\n",
        "    # TODO: Finish the in epoch training process here.                #\n",
        "    ###################################################################\n",
        "    # Replace \"pass\" statement with your code\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "    model_outputs = model(inputs)\n",
        "    loss = loss_function(model_outputs, labels)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    ###################################################################\n",
        "    #                     END OF YOUR CODE                            #\n",
        "    ###################################################################\n",
        "    return model_outputs, loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BFpkBkSciHUs"
      },
      "source": [
        "# Questions for Problem 4"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NRbFFkSyiHUt"
      },
      "source": [
        "Let's try some real applications with Pytorch. In this section, we will directly use Pytoch functions to build a LeNet-5 model. Then we test the model on MNIST dataset. Your task is to compute the lacked `Output Size` and finish building the architecture in **Code Blocks for Problem 4**. We will use functions like Linear, Conv2d, ReLU, MaxPool2d in Pytorch. Refer to [https://pytorch.org/docs/stable/nn.functional.html](https://pytorch.org/docs/stable/nn.functional.html) for more information."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "button": false,
        "deletable": true,
        "id": "aQW_w1Wzw72f",
        "new_sheet": false,
        "run_control": {
          "read_only": false
        },
        "tags": [
          "pdf-title"
        ]
      },
      "source": [
        "# LeNet-5\n",
        "\n",
        "The following Table shows the LeNet-5 model architecture and part of the output sizes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HUdOTIaniHUt"
      },
      "source": [
        "\n",
        "|Layer|Output Size|\n",
        "|----|----|\n",
        "|$Input$|1\\*28\\*28|\n",
        "|$Conv(C_{out}=20, K=5, P=2, S=1)$||\n",
        "|$ReLU$||\n",
        "|$MaxPool(K=2, S=2)$||\n",
        "|$Conv(C_{out}=50, K=5, P=2, S=1)$||\n",
        "|$ReLU$||\n",
        "|$MaxPool(K=2, S=2)$||\n",
        "|$Flatten$||\n",
        "|$Linear$|500|\n",
        "|$ReLU$|500|\n",
        "|$Linear$|10|"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PqxkisVbiHUt",
        "outputId": "a43f44fa-c08d-48ae-bba4-7a213e6adc5d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LeNet Model: \n",
            "LeNet(\n",
            "  (conv1): Conv2d(1, 20, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
            "  (conv2): Conv2d(20, 50, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
            "  (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (fc1): Linear(in_features=2450, out_features=500, bias=True)\n",
            "  (fc2): Linear(in_features=500, out_features=10, bias=True)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "print(\"LeNet Model: \")\n",
        "model = LeNet()\n",
        "print(model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zPpvgMTmiHUt"
      },
      "source": [
        "Let's start testing our model on MNIST dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "90Gx1TTViHUt",
        "outputId": "505e546b-fc41-4b83-9db5-ae4715616158"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0\n",
            "Training loss: 0.18237850069999695\n",
            "Training Acc: 0.9428833333333333\n",
            "Validation loss: 0.11201713234186172\n",
            "Validation Acc: 0.9677\n",
            "Epoch 1\n",
            "Training loss: 0.09535914659500122\n",
            "Training Acc: 0.9726333333333333\n",
            "Validation loss: 0.09736984223127365\n",
            "Validation Acc: 0.9717\n",
            "Epoch 2\n",
            "Training loss: 0.0773555338382721\n",
            "Training Acc: 0.9776333333333334\n",
            "Validation loss: 0.09346228837966919\n",
            "Validation Acc: 0.9747\n",
            "Epoch 3\n",
            "Training loss: 0.08146487921476364\n",
            "Training Acc: 0.9778833333333333\n",
            "Validation loss: 0.07830006629228592\n",
            "Validation Acc: 0.9773\n",
            "Epoch 4\n",
            "Training loss: 0.08177363872528076\n",
            "Training Acc: 0.9772166666666666\n",
            "Validation loss: 0.09612464159727097\n",
            "Validation Acc: 0.9752\n",
            "Epoch 5\n",
            "Training loss: 0.07544002681970596\n",
            "Training Acc: 0.97905\n",
            "Validation loss: 0.09381267428398132\n",
            "Validation Acc: 0.9762\n",
            "Epoch 6\n",
            "Training loss: 0.07365214824676514\n",
            "Training Acc: 0.9802166666666666\n",
            "Validation loss: 0.07499419152736664\n",
            "Validation Acc: 0.9795\n",
            "Epoch 7\n",
            "Training loss: 0.06126044690608978\n",
            "Training Acc: 0.9832166666666666\n",
            "Validation loss: 0.12745316326618195\n",
            "Validation Acc: 0.9758\n",
            "Epoch 8\n",
            "Training loss: 0.0683746263384819\n",
            "Training Acc: 0.9829833333333333\n",
            "Validation loss: 0.10142706334590912\n",
            "Validation Acc: 0.9751\n",
            "Epoch 9\n",
            "Training loss: 0.07190366089344025\n",
            "Training Acc: 0.9819166666666667\n",
            "Validation loss: 0.11280733346939087\n",
            "Validation Acc: 0.9729\n"
          ]
        }
      ],
      "source": [
        "import torch.optim as optim\n",
        "import torchvision.datasets as datasets\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.nn as nn\n",
        "import torch\n",
        "\n",
        "# hyperparameters\n",
        "learning_rate = 0.01\n",
        "num_epochs = 10\n",
        "\n",
        "# load dataset\n",
        "train_dataset = datasets.MNIST(root='dataset/', train=True,\n",
        "                               transform=transforms.Compose([transforms.ToTensor()]), download=True)\n",
        "test_dataset = datasets.MNIST(root='dataset/', train=False,\n",
        "                              transform=transforms.Compose([transforms.ToTensor()]), download=True)\n",
        "\n",
        "train_loader = DataLoader(dataset=train_dataset, batch_size=64, shuffle=True)\n",
        "test_loader = DataLoader(dataset=test_dataset, batch_size=64)\n",
        "dataset_sizes = {'train':len(train_dataset), 'test':len(test_dataset)}\n",
        "\n",
        "# load model\n",
        "model = LeNet().cuda()\n",
        "\n",
        "# define loss\n",
        "ce_loss = nn.CrossEntropyLoss()\n",
        "\n",
        "# define optimizer\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "# start training\n",
        "for epoch in range(num_epochs):\n",
        "\n",
        "    print('Epoch', epoch)\n",
        "    running_loss = 0.0\n",
        "    valid_loss = 0.0\n",
        "    model.train()\n",
        "\n",
        "    correct = 0\n",
        "    for data in train_loader: # dataloaders[0] is train loader\n",
        "\n",
        "        inputs, labels  = data\n",
        "        batch_size = inputs.shape[0]\n",
        "\n",
        "        inputs = inputs.cuda()\n",
        "        labels = labels.cuda()\n",
        "\n",
        "        model_outputs, loss = train_epoch(inputs, labels, optimizer, ce_loss)\n",
        "\n",
        "        correct += (torch.argmax(model_outputs,dim=1)==labels).sum().item()\n",
        "        running_loss += loss.data * batch_size\n",
        "\n",
        "    epoch_loss = running_loss / len(train_dataset)\n",
        "    print('Training loss:', epoch_loss.item())\n",
        "    print('Training Acc:', correct/len(train_dataset))\n",
        "\n",
        "    # evaluation each epoch\n",
        "    model.eval()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        correct = 0\n",
        "        for data in test_loader:\n",
        "            inputs, labels  = data\n",
        "            batch_size = inputs.shape[0]\n",
        "\n",
        "            inputs = inputs.cuda()\n",
        "            labels = labels.cuda()\n",
        "\n",
        "            outputs = model(inputs)\n",
        "            optimizer.zero_grad()\n",
        "            loss = ce_loss(outputs, labels)\n",
        "\n",
        "            correct += (torch.argmax(outputs,dim=1)==labels).sum().item()\n",
        "            valid_loss += loss.data * batch_size\n",
        "\n",
        "        epoch_valid_loss = valid_loss / len(test_dataset)\n",
        "        print('Validation loss:', epoch_valid_loss.item())\n",
        "        print('Validation Acc:', correct/len(test_dataset))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
