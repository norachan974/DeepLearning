{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zNmLmqrJAXXp"
      },
      "source": [
        "# LIS 640 Applied Deep Learning : Backpropagation\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YiCtRax98sPk"
      },
      "source": [
        "# Code Blocks for Problem 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "WaT3A7je8sPl"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import random\n",
        "import statistics\n",
        "from typing import Dict, List, Callable, Optional\n",
        "\n",
        "\n",
        "def hello_two_layer_net():\n",
        "    print(\"Hello from problem2.ipynb!\")\n",
        "\n",
        "\n",
        "def sample_batch(\n",
        "    X: torch.Tensor, y: torch.Tensor, num_train: int, batch_size: int\n",
        "):\n",
        "    \"\"\"\n",
        "    Sample batch_size elements from the training data and their\n",
        "    corresponding labels to use in this round of gradient descent.\n",
        "    \"\"\"\n",
        "    indices = torch.randint(num_train, (batch_size,))\n",
        "    y_batch = y[indices]\n",
        "    X_batch = X[indices]\n",
        "    return X_batch, y_batch\n",
        "\n",
        "\n",
        "# Template class modules that we will use later: Do not edit/modify this class\n",
        "class TwoLayerNet(object):\n",
        "    def __init__(\n",
        "        self,\n",
        "        input_size: int,\n",
        "        hidden_size: int,\n",
        "        output_size: int,\n",
        "        dtype: torch.dtype = torch.float32,\n",
        "        device: str = \"cuda\",\n",
        "        std: float = 1e-4,\n",
        "    ):\n",
        "        \"\"\"\n",
        "        Initialize the model. Weights are initialized to small random values and\n",
        "        biases are initialized to zero. Weights and biases are stored in the\n",
        "        variable self.params, which is a dictionary with the following keys:\n",
        "\n",
        "        W1: First layer weights; has shape (D, H)\n",
        "        W2: Second layer weights; has shape (H, C)\n",
        "\n",
        "        Inputs:\n",
        "        - input_size: The dimension D of the input data.\n",
        "        - hidden_size: The number of neurons H in the hidden layer.\n",
        "        - output_size: The number of classes C.\n",
        "        - dtype: Optional, data type of each initial weight params\n",
        "        - device: Optional, whether the weight params is on GPU or CPU\n",
        "        - std: Optional, initial weight scaler.\n",
        "        \"\"\"\n",
        "        # reset seed before start\n",
        "        random.seed(0)\n",
        "        torch.manual_seed(0)\n",
        "\n",
        "        self.params = {}\n",
        "        self.params[\"W1\"] = std * torch.randn(\n",
        "            input_size, hidden_size, dtype=dtype, device=device\n",
        "        )\n",
        "        self.params[\"W2\"] = std * torch.randn(\n",
        "            hidden_size, output_size, dtype=dtype, device=device\n",
        "        )\n",
        "\n",
        "    def loss(\n",
        "        self,\n",
        "        X: torch.Tensor,\n",
        "        y: Optional[torch.Tensor] = None,\n",
        "        reg: float = 0.0,\n",
        "    ):\n",
        "        return nn_forward_backward(self.params, X, y, reg)\n",
        "\n",
        "    def train(\n",
        "        self,\n",
        "        X: torch.Tensor,\n",
        "        y: torch.Tensor,\n",
        "        X_val: torch.Tensor,\n",
        "        y_val: torch.Tensor,\n",
        "        learning_rate: float = 1e-3,\n",
        "        learning_rate_decay: float = 0.95,\n",
        "        reg: float = 5e-6,\n",
        "        num_iters: int = 100,\n",
        "        batch_size: int = 200,\n",
        "        verbose: bool = False,\n",
        "    ):\n",
        "        # fmt: off\n",
        "        return nn_train(\n",
        "            self.params, nn_forward_backward, nn_predict, X, y,\n",
        "            X_val, y_val, learning_rate, learning_rate_decay,\n",
        "            reg, num_iters, batch_size, verbose,\n",
        "        )\n",
        "        # fmt: on\n",
        "\n",
        "    def predict(self, X: torch.Tensor):\n",
        "        return nn_predict(self.params, nn_forward_backward, X)\n",
        "\n",
        "    def save(self, path: str):\n",
        "        torch.save(self.params, path)\n",
        "        print(\"Saved in {}\".format(path))\n",
        "\n",
        "    def load(self, path: str):\n",
        "        checkpoint = torch.load(path, map_location=\"cpu\")\n",
        "        self.params = checkpoint\n",
        "        if len(self.params) != 4:\n",
        "            raise Exception(\"Failed to load your checkpoint\")\n",
        "\n",
        "        for param in [\"W1\", \"W2\"]:\n",
        "            if param not in self.params:\n",
        "                raise Exception(\"Failed to load your checkpoint\")\n",
        "        # print(\"load checkpoint file: {}\".format(path))\n",
        "\n",
        "\n",
        "def nn_forward_pass(params: Dict[str, torch.Tensor], X: torch.Tensor):\n",
        "    \"\"\"\n",
        "    The first stage of our neural network implementation: Run the forward pass\n",
        "    of the network to compute the hidden layer features and classification\n",
        "    scores. The network architecture should be:\n",
        "\n",
        "    FC layer -> ReLU (hidden) -> FC layer (scores)\n",
        "\n",
        "    Inputs:\n",
        "    - params: a dictionary of PyTorch Tensor that store the weights of a model.\n",
        "      It should have following keys with shape\n",
        "          W1: First layer weights; has shape (D, H)\n",
        "          W2: Second layer weights; has shape (H, C)\n",
        "    - X: Input data of shape (N, D). Each X[i] is a training sample.\n",
        "\n",
        "    Returns a tuple of:\n",
        "    - scores: Tensor of shape (N, C) giving the classification scores for X\n",
        "    - hidden: Tensor of shape (N, H) giving the hidden layer representation\n",
        "      for each input value (after the ReLU).\n",
        "    \"\"\"\n",
        "    # Unpack variables from the params dictionary\n",
        "    W1 = params[\"W1\"]\n",
        "    W2 = params[\"W2\"]\n",
        "    N, D = X.shape\n",
        "\n",
        "    # Compute the forward pass\n",
        "    hidden = None\n",
        "    scores = None\n",
        "    ############################################################################\n",
        "    # TODO: Perform the forward pass, computing the class scores for the input.#\n",
        "    # Store the result in the scores variable, which should be an tensor of    #\n",
        "    # shape (N, C).                                                            #\n",
        "    ############################################################################\n",
        "    # Replace \"pass\" statement with your code\n",
        "    hidden_pre_activation = X.mm(W1)\n",
        "    hidden = torch.relu(hidden_pre_activation)\n",
        "    scores = hidden.mm(W2)\n",
        "    ###########################################################################\n",
        "    #                             END OF YOUR CODE                            #\n",
        "    ###########################################################################\n",
        "\n",
        "    return scores, hidden\n",
        "\n",
        "\n",
        "def nn_forward_backward(\n",
        "    params: Dict[str, torch.Tensor],\n",
        "    X: torch.Tensor,\n",
        "    y: Optional[torch.Tensor] = None,\n",
        "    reg: float = 0.0\n",
        "):\n",
        "    \"\"\"\n",
        "    Compute the loss and gradients for a two layer fully connected neural\n",
        "    network. When you implement loss and gradient, please don't forget to\n",
        "    scale the losses/gradients by the batch size.\n",
        "\n",
        "    Inputs: First two parameters (params, X) are same as nn_forward_pass\n",
        "    - params: a dictionary of PyTorch Tensor that store the weights of a model.\n",
        "      It should have following keys with shape\n",
        "          W1: First layer weights; has shape (D, H)\n",
        "          W2: Second layer weights; has shape (H, C)\n",
        "    - X: Input data of shape (N, D). Each X[i] is a training sample.\n",
        "    - y: Vector of training labels. y[i] is the label for X[i], and each y[i] is\n",
        "      an integer in the range 0 <= y[i] < C. This parameter is optional; if it\n",
        "      is not passed then we only return scores, and if it is passed then we\n",
        "      instead return the loss and gradients.\n",
        "    - reg: Regularization strength.\n",
        "\n",
        "    Returns:\n",
        "    If y is None, return a tensor scores of shape (N, C) where scores[i, c] is\n",
        "    the score for class c on input X[i].\n",
        "\n",
        "    If y is not None, instead return a tuple of:\n",
        "    - loss: Loss (data loss and regularization loss) for this batch of training\n",
        "      samples.\n",
        "    - grads: Dictionary mapping parameter names to gradients of those parameters\n",
        "      with respect to the loss function; has the same keys as self.params.\n",
        "    \"\"\"\n",
        "    # Unpack variables from the params dictionary\n",
        "    W1 = params[\"W1\"]\n",
        "    W2 = params[\"W2\"]\n",
        "    N, D = X.shape\n",
        "\n",
        "    scores, h1 = nn_forward_pass(params, X)\n",
        "    # If the targets are not given then jump out, we're done\n",
        "    if y is None:\n",
        "        return scores\n",
        "\n",
        "    # Compute the loss\n",
        "    loss = None\n",
        "    ############################################################################\n",
        "    # TODO: Compute the loss, based on the results from nn_forward_pass.       #\n",
        "    ############################################################################\n",
        "    # Replace \"pass\" statement with your code\n",
        "    exp = torch.exp(scores - torch.max(scores, axis=1, keepdims=True).values)\n",
        "    probs = exp / torch.sum(exp, axis=1, keepdims=True)\n",
        "    correct_logprobs = -torch.log(probs[range(N), y] + 1e-7)\n",
        "    data_loss = torch.sum(correct_logprobs) / N\n",
        "\n",
        "    reg_loss = reg * 0.5 * (torch.sum(W1 * W1) + torch.sum(W2 * W2))\n",
        "    loss = data_loss + reg_loss\n",
        "    ###########################################################################\n",
        "    #                             END OF YOUR CODE                            #\n",
        "    ###########################################################################\n",
        "\n",
        "    # Backward pass: compute gradients\n",
        "    grads = {}\n",
        "    ###########################################################################\n",
        "    # TODO: Compute the backward pass, computing the derivatives of the       #\n",
        "    # weights and biases. Store the results in the grads dictionary.          #\n",
        "    # For example, grads['W1'] should store the gradient on W1, and be a      #\n",
        "    # tensor of same size                                                     #\n",
        "    ###########################################################################\n",
        "    # Replace \"pass\" statement with your code\n",
        "    dscores = probs\n",
        "    dscores[range(N), y] -= 1\n",
        "    dscores /= N\n",
        "    dW2 = h1.t().mm(dscores)\n",
        "    dW2 += reg * W2\n",
        "    grads['W2'] = dW2\n",
        "    dhidden = dscores.mm(W2.t())\n",
        "    dhidden[h1 <= 0] = 0\n",
        "    dW1 = X.t().mm(dhidden)\n",
        "    dW1 += reg * W1\n",
        "    grads['W1'] = dW1\n",
        "    ###########################################################################\n",
        "    #                             END OF YOUR CODE                            #\n",
        "    ###########################################################################\n",
        "\n",
        "    return loss, grads\n",
        "\n",
        "\n",
        "def nn_train(\n",
        "    params: Dict[str, torch.Tensor],\n",
        "    loss_func: Callable,\n",
        "    pred_func: Callable,\n",
        "    X: torch.Tensor,\n",
        "    y: torch.Tensor,\n",
        "    X_val: torch.Tensor,\n",
        "    y_val: torch.Tensor,\n",
        "    learning_rate: float = 1e-3,\n",
        "    learning_rate_decay: float = 0.95,\n",
        "    reg: float = 5e-6,\n",
        "    num_iters: int = 100,\n",
        "    batch_size: int = 200,\n",
        "    verbose: bool = False,\n",
        "):\n",
        "    \"\"\"\n",
        "    Train this neural network using stochastic gradient descent.\n",
        "\n",
        "    Inputs:\n",
        "    - params: a dictionary of PyTorch Tensor that store the weights of a model.\n",
        "      It should have following keys with shape\n",
        "          W1: First layer weights; has shape (D, H)\n",
        "          W2: Second layer weights; has shape (H, C)\n",
        "    - loss_func: a loss function that computes the loss and the gradients.\n",
        "      It takes as input:\n",
        "      - params: Same as input to nn_train\n",
        "      - X_batch: A minibatch of inputs of shape (B, D)\n",
        "      - y_batch: Ground-truth labels for X_batch\n",
        "      - reg: Same as input to nn_train\n",
        "      And it returns a tuple of:\n",
        "        - loss: Scalar giving the loss on the minibatch\n",
        "        - grads: Dictionary mapping parameter names to gradients of the loss with\n",
        "          respect to the corresponding parameter.\n",
        "    - pred_func: prediction function that im\n",
        "    - X: A PyTorch tensor of shape (N, D) giving training data.\n",
        "    - y: A PyTorch tensor of shape (N,) giving training labels; y[i] = c means\n",
        "      that X[i] has label c, where 0 <= c < C.\n",
        "    - X_val: A PyTorch tensor of shape (N_val, D) giving validation data.\n",
        "    - y_val: A PyTorch tensor of shape (N_val,) giving validation labels.\n",
        "    - learning_rate: Scalar giving learning rate for optimization.\n",
        "    - learning_rate_decay: Scalar giving factor used to decay the learning rate\n",
        "      after each epoch.\n",
        "    - reg: Scalar giving regularization strength.\n",
        "    - num_iters: Number of steps to take when optimizing.\n",
        "    - batch_size: Number of training examples to use per step.\n",
        "    - verbose: boolean; if true print progress during optimization.\n",
        "\n",
        "    Returns: A dictionary giving statistics about the training process\n",
        "    \"\"\"\n",
        "    num_train = X.shape[0]\n",
        "    iterations_per_epoch = max(num_train // batch_size, 1)\n",
        "\n",
        "    # Use SGD to optimize the parameters in self.model\n",
        "    loss_history = []\n",
        "    train_acc_history = []\n",
        "    val_acc_history = []\n",
        "\n",
        "    for it in range(num_iters):\n",
        "        X_batch, y_batch = sample_batch(X, y, num_train, batch_size)\n",
        "\n",
        "        # Compute loss and gradients using the current minibatch\n",
        "        loss, grads = loss_func(params, X_batch, y=y_batch, reg=reg)\n",
        "        loss_history.append(loss.item())\n",
        "\n",
        "        #########################################################################\n",
        "        # TODO: Use the gradients in the grads dictionary to update the         #\n",
        "        # parameters of the network (stored in the dictionary self.params)      #\n",
        "        # using stochastic gradient descent. You'll need to use the gradients   #\n",
        "        # stored in the grads dictionary defined above.                         #\n",
        "        #########################################################################\n",
        "        # Replace \"pass\" statement with your code\n",
        "        for param_name in params:\n",
        "            params[param_name] -= learning_rate * grads[param_name]\n",
        "        #########################################################################\n",
        "        #                             END OF YOUR CODE                          #\n",
        "        #########################################################################\n",
        "\n",
        "        if verbose and it % 100 == 0:\n",
        "            print(\"iteration %d / %d: loss %f\" % (it, num_iters, loss.item()))\n",
        "\n",
        "        # Every epoch, check train and val accuracy and decay learning rate.\n",
        "        if it % iterations_per_epoch == 0:\n",
        "            # Check accuracy\n",
        "            y_train_pred = pred_func(params, loss_func, X_batch)\n",
        "            train_acc = (y_train_pred == y_batch).float().mean().item()\n",
        "            y_val_pred = pred_func(params, loss_func, X_val)\n",
        "            val_acc = (y_val_pred == y_val).float().mean().item()\n",
        "            train_acc_history.append(train_acc)\n",
        "            val_acc_history.append(val_acc)\n",
        "\n",
        "            # Decay learning rate\n",
        "            learning_rate *= learning_rate_decay\n",
        "\n",
        "    return {\n",
        "        \"loss_history\": loss_history,\n",
        "        \"train_acc_history\": train_acc_history,\n",
        "        \"val_acc_history\": val_acc_history,\n",
        "    }\n",
        "\n",
        "\n",
        "def nn_predict(\n",
        "    params: Dict[str, torch.Tensor], loss_func: Callable, X: torch.Tensor\n",
        "):\n",
        "    \"\"\"\n",
        "    Use the trained weights of this two-layer network to predict labels for\n",
        "    data points. For each data point we predict scores for each of the C\n",
        "    classes, and assign each data point to the class with the highest score.\n",
        "\n",
        "    Inputs:\n",
        "    - params: a dictionary of PyTorch Tensor that store the weights of a model.\n",
        "      It should have following keys with shape\n",
        "          W1: First layer weights; has shape (D, H)\n",
        "          W2: Second layer weights; has shape (H, C)\n",
        "    - loss_func: a loss function that computes the loss and the gradients\n",
        "    - X: A PyTorch tensor of shape (N, D) giving N D-dimensional data points to\n",
        "      classify.\n",
        "\n",
        "    Returns:\n",
        "    - y_pred: A PyTorch tensor of shape (N,) giving predicted labels for each of\n",
        "      the elements of X. For all i, y_pred[i] = c means that X[i] is predicted\n",
        "      to have class c, where 0 <= c < C.\n",
        "    \"\"\"\n",
        "    y_pred = None\n",
        "    results,_ = nn_forward_pass(params, X)\n",
        "    _, y_pred =  results.max(dim = 1)\n",
        "    return y_pred"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JaVLlBaU8sPn"
      },
      "source": [
        "# Questions for Problem 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G3v88O9o8sPo"
      },
      "source": [
        "# Set up code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "O3EvIZ0uAOVN"
      },
      "outputs": [],
      "source": [
        "import utils\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "\n",
        "plt.rcParams['figure.figsize'] = (10.0, 8.0)\n",
        "plt.rcParams['font.size'] = 16\n",
        "plt.rcParams['image.interpolation'] = 'nearest'\n",
        "plt.rcParams['image.cmap'] = 'gray'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hbe3wUpVAjma"
      },
      "source": [
        "# Implementing a Two-Layer Network\n",
        "In this exercise we will develop a Two-Layer Network with fully-connected layers to perform classification, and test it out on the MNIST dataset.\n",
        "\n",
        "We train the network with a Cross-Entropy loss function. The network uses a ReLU activation function after the first fully connected layer.\n",
        "\n",
        "In other words, the network has the following architecture:\n",
        "\n",
        "  input - fully connected layer - ReLU - fully connected layer - Softmax - Cross-Entropy\n",
        "\n",
        "We denote the input example as $x$, the ground truth label as $y$, the first fully connected layer output as $h$, the activation function output as $a$ and the second fully connected layer output as $s$. The complete process of the two-layer network is illustrated below.\n",
        "\n",
        "$h = W_1^Tx$\n",
        "\n",
        "$a = ReLU(h)$\n",
        "\n",
        "$s = W_2^Ta$\n",
        "\n",
        "$loss = CrossEntropy(softmax(s),y)$\n",
        "\n",
        "Here $softmax(z)_i=\\frac{e^{z_i}}{\\sum^K_{j=1}e^{z_j}}$ and $CrossEntropy(y',y)=-\\sum_i y'_i log(y_i)$.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lJqim3P1qZgv"
      },
      "source": [
        "## Play with a toy data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5T-4Phbd9GvI"
      },
      "source": [
        "The inputs to our network will be a batch of $N$ (`num_inputs`) $D$-dimensional vectors (`input_size`); the hidden layer will have $H$ hidden units (`hidden_size`), and we will predict classification scores for $C$ categories (`num_classes`). This means that the learnable weights of the network will have the following shapes:\n",
        "\n",
        "*   W1: First layer weights; has shape (D, H)\n",
        "*   W2: Second layer weights; has shape (H, C)\n",
        "\n",
        "We will use `utils.get_toy_data` function to generate random weights for a small toy model while we implement the model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZLdCF3B-AOVT"
      },
      "source": [
        "### Forward pass: compute scores\n",
        "We want to write a function that takes as input the model weights and a batch of images and labels, and returns the loss and the gradient of the loss with respect to each model parameter.\n",
        "\n",
        "However rather than attempting to implement the entire function at once, we will take a staged approach and ask you to implement the full forward and backward pass one step at a time.\n",
        "\n",
        "First we will implement the forward pass of the network which uses the weights and biases to compute scores for all inputs in `nn_forward_pass`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "inlH2l-XEtZQ"
      },
      "source": [
        "Compute the scores and compare with the answer. The distance gap should be smaller than 1e-10."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tZV9_3ZWAOVU",
        "outputId": "e43f0d51-072d-47c5-f964-c4634628d7b6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Your scores:\n",
            "tensor([[ 9.7003e-08, -1.1143e-07, -3.9961e-08],\n",
            "        [-7.4297e-08,  1.1502e-07,  1.5685e-07],\n",
            "        [-2.5860e-07,  2.2765e-07,  3.2453e-07],\n",
            "        [-4.7257e-07,  9.0935e-07,  4.0368e-07],\n",
            "        [-1.8395e-07,  7.9303e-08,  6.0360e-07]], device='cuda:0')\n",
            "torch.float32\n",
            "\n",
            "correct scores:\n",
            "tensor([[ 9.7003e-08, -1.1143e-07, -3.9961e-08],\n",
            "        [-7.4297e-08,  1.1502e-07,  1.5685e-07],\n",
            "        [-2.5860e-07,  2.2765e-07,  3.2453e-07],\n",
            "        [-4.7257e-07,  9.0935e-07,  4.0368e-07],\n",
            "        [-1.8395e-07,  7.9303e-08,  6.0360e-07]], device='cuda:0')\n",
            "\n",
            "Difference between your scores and correct scores: 2.24e-11\n"
          ]
        }
      ],
      "source": [
        "import utils\n",
        "\n",
        "utils.reset_seed(0)\n",
        "toy_X, toy_y, params = utils.get_toy_data()\n",
        "\n",
        "# YOUR_TURN: Implement the score computation part of nn_forward_pass\n",
        "scores, _ = nn_forward_pass(params, toy_X)\n",
        "print('Your scores:')\n",
        "print(scores)\n",
        "print(scores.dtype)\n",
        "print()\n",
        "print('correct scores:')\n",
        "correct_scores = torch.tensor([\n",
        "        [ 9.7003e-08, -1.1143e-07, -3.9961e-08],\n",
        "        [-7.4297e-08,  1.1502e-07,  1.5685e-07],\n",
        "        [-2.5860e-07,  2.2765e-07,  3.2453e-07],\n",
        "        [-4.7257e-07,  9.0935e-07,  4.0368e-07],\n",
        "        [-1.8395e-07,  7.9303e-08,  6.0360e-07]], dtype=torch.float32, device=scores.device)\n",
        "print(correct_scores)\n",
        "print()\n",
        "\n",
        "# The difference should be very small. We get < 1e-10\n",
        "scores_diff = (scores - correct_scores).abs().sum().item()\n",
        "print('Difference between your scores and correct scores: %.2e' % scores_diff)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7XNJ3ydEAOVW"
      },
      "source": [
        "### Forward pass: compute loss\n",
        "Now, we implement the first part of `nn_forward_backward` that computes the loss.\n",
        "\n",
        "For the data loss, we compute the Cross-Entropy loss. Note that the final loss shold be an average loss of $N$ input examples."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C734SdJGE6xh"
      },
      "source": [
        "First, Let's run the following to check your implementation.\n",
        "\n",
        "We compute the loss for the toy data, and compare with the answer computed by our implementation. The difference between the correct and computed loss should be less than `1e-4`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wgG6w2uKAOVX",
        "outputId": "0f49e952-7b4b-4a9a-a833-15bca70e3105"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Your loss:  1.0986119508743286\n",
            "Correct loss:  1.0986121892929077\n",
            "Difference: 2.3842e-07\n"
          ]
        }
      ],
      "source": [
        "import utils\n",
        "\n",
        "utils.reset_seed(0)\n",
        "toy_X, toy_y, params = utils.get_toy_data()\n",
        "\n",
        "# YOUR_TURN: Implement the loss computation part of nn_forward_backward\n",
        "loss, _ = nn_forward_backward(params, toy_X, toy_y)\n",
        "print('Your loss: ', loss.item())\n",
        "correct_loss = 1.0986121892929077\n",
        "print('Correct loss: ', correct_loss)\n",
        "diff = (correct_loss - loss).item()\n",
        "\n",
        "# should be very small, we get < 1e-4\n",
        "print('Difference: %.4e' % diff)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vExP-7n3AOVa"
      },
      "source": [
        "### Backward pass\n",
        "Now implement the backward pass for the entire network in `nn_forward_backward`.\n",
        "\n",
        "After doing so, we will use numeric gradient checking to see whether the analytic gradient computed by our backward pass mateches a numeric gradient.\n",
        "\n",
        "We will use the functions `utils.compute_numeric_gradient` and `utils.rel_error` to help with numeric gradient checking.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uez6T8KC8sPq"
      },
      "source": [
        "Hint: For gradient computation of Softmax Cross-Entropy loss, please refer to https://www.michaelpiseno.com/blog/2021/softmax-gradient/."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "93oOdibtW_Kl"
      },
      "source": [
        "Now we will compute the gradient of the loss with respect to the variables `W1` and `W2`. Now that you (hopefully!) have a correctly implemented forward pass, you can debug your backward pass using a numeric gradient check.\n",
        "\n",
        "You should see relative errors less than `1e-4` for all parameters."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qCEkprvoAOVb",
        "outputId": "f5c0dec4-517f-4933-bedf-fbcbf65a79ec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "W2 max relative error: 1.278115e-06\n",
            "W1 max relative error: 1.368676e-06\n"
          ]
        }
      ],
      "source": [
        "import utils\n",
        "\n",
        "utils.reset_seed(0)\n",
        "\n",
        "toy_X, toy_y, params = utils.get_toy_data(dtype=torch.float64)\n",
        "\n",
        "# YOUR_TURN: Implement the gradient computation part of nn_forward_backward\n",
        "#            When you implement the gradient computation part, you may need to\n",
        "#            implement the `hidden` output in nn_forward_pass, as well.\n",
        "loss, grads = nn_forward_backward(params, toy_X, toy_y)\n",
        "\n",
        "for param_name, grad in grads.items():\n",
        "  param = params[param_name]\n",
        "  f = lambda w: nn_forward_backward(params, toy_X, toy_y)[0]\n",
        "  grad_numeric = utils.compute_numeric_gradient(f, param)\n",
        "  error = utils.rel_error(grad, grad_numeric)\n",
        "  print('%s max relative error: %e' % (param_name, error))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LjAUalCBAOVd"
      },
      "source": [
        "### Train the network\n",
        "To train the network we will use stochastic gradient descent (SGD).\n",
        "\n",
        "Look at the function `nn_train` and fill in the missing sections to implement the training procedure.\n",
        "\n",
        "Once you have implemented the method, run the code below to train a two-layer network on toy data. Your final training loss should be less than 1.0."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 754
        },
        "id": "Wgw06cLXAOVd",
        "outputId": "4b3fd652-955e-4435-a18a-f22d516208a3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final training loss:  0.6050100326538086\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x800 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "import utils\n",
        "from utils import get_toy_data\n",
        "\n",
        "utils.reset_seed(0)\n",
        "toy_X, toy_y, params = get_toy_data()\n",
        "\n",
        "# YOUR_TURN: Implement the nn_train function.\n",
        "#            You may need to check nn_predict function (the \"pred_func\") as well.\n",
        "stats = nn_train(params, nn_forward_backward, nn_predict, toy_X, toy_y, toy_X, toy_y,\n",
        "                 learning_rate=1e-1, reg=1e-6,\n",
        "                 num_iters=200, verbose=False)\n",
        "\n",
        "print('Final training loss: ', stats['loss_history'][-1])\n",
        "\n",
        "# plot the loss history\n",
        "plt.plot(stats['loss_history'], 'o')\n",
        "plt.xlabel('Iteration')\n",
        "plt.ylabel('training loss')\n",
        "plt.title('Training Loss history')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8cPIajWNAOVg"
      },
      "source": [
        "## Testing our NN on a real dataset: MNIST\n",
        "Now that you have implemented a two-layer network that passes gradient checks and works on toy data, it's time to load up our MNIST data so we can use it to train a classifier on a real dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lYo_XrU3AOVg",
        "outputId": "34aa4745-22e0-4e2d-e0e6-52d8563177e9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to dataset/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|| 9912422/9912422 [00:00<00:00, 127934319.18it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting dataset/MNIST/raw/train-images-idx3-ubyte.gz to dataset/MNIST/raw\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to dataset/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|| 28881/28881 [00:00<00:00, 114711831.27it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting dataset/MNIST/raw/train-labels-idx1-ubyte.gz to dataset/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to dataset/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|| 1648877/1648877 [00:00<00:00, 76550644.17it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting dataset/MNIST/raw/t10k-images-idx3-ubyte.gz to dataset/MNIST/raw\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to dataset/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|| 4542/4542 [00:00<00:00, 4303259.27it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting dataset/MNIST/raw/t10k-labels-idx1-ubyte.gz to dataset/MNIST/raw\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import utils\n",
        "\n",
        "\n",
        "# Invoke the above function to get our data.\n",
        "utils.reset_seed(0)\n",
        "x_train, y_train, x_val, y_val = utils.load_data()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cq-HkgRBAOVQ"
      },
      "source": [
        "### Wrap all function into a Class\n",
        "We will use the class `TwoLayerNet` to represent instances of our network. The network parameters are stored in the instance variable `self.params` where keys are string parameter names and values are PyTorch tensors.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_CsYAv3uAOVi"
      },
      "source": [
        "### Train a network\n",
        "To train our network we will use SGD. In addition, we will adjust the learning rate with an exponential learning rate schedule as optimization proceeds; after each epoch, we will reduce the learning rate by multiplying it by a decay rate."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hgg0QV9DAOVj",
        "outputId": "fed1246f-1784-48bb-d8a0-3dceb9d40833"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "iteration 0 / 500: loss 2.302584\n",
            "iteration 100 / 500: loss 2.301893\n",
            "iteration 200 / 500: loss 1.799361\n",
            "iteration 300 / 500: loss 0.858400\n",
            "iteration 400 / 500: loss 0.635817\n",
            "Validation accuracy: 85.97%\n"
          ]
        }
      ],
      "source": [
        "import utils\n",
        "\n",
        "input_size = 1 * 28 * 28\n",
        "hidden_size = 36\n",
        "num_classes = 10\n",
        "\n",
        "# fix random seed before we generate a set of parameters\n",
        "utils.reset_seed(0)\n",
        "net = TwoLayerNet(input_size, hidden_size, num_classes, dtype=torch.float32, device='cpu')\n",
        "\n",
        "# Train the network\n",
        "stats = net.train(x_train, y_train,\n",
        "                  x_val, y_val,\n",
        "                  num_iters=500, batch_size=1000,\n",
        "                  learning_rate=1e-1, learning_rate_decay=0.95,\n",
        "                  verbose=True)\n",
        "\n",
        "# Predict on the validation set\n",
        "y_val_pred = net.predict(x_val)\n",
        "val_acc = 100.0 * (y_val_pred == y_val).double().mean().item()\n",
        "print('Validation accuracy: %.2f%%' % val_acc)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
